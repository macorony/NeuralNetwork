{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg2J2d3Tpjq9orOxyvR0Dv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/macorony/NeuralNetwork/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gi-EGr-IqGaQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic"
      ],
      "metadata": {
        "id": "m6l0IeUI96lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.zeros(5,3)\n",
        "print(z)\n",
        "print(z.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQJWekD4q1Oh",
        "outputId": "4bbab837-9134-41f7-abf9-3f20e0c93bad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.ones((5,3), dtype=torch.int16)\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0OdN2-ivVAY",
        "outputId": "c4007a53-5653-47e2-bfe6-19b718b5396d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1729)\n",
        "r1 = torch.rand(2,2)\n",
        "print(r1)\n",
        "\n",
        "r2 = torch.rand(2,2)\n",
        "print(r2)\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "r3 = torch.rand(2,2)\n",
        "print(r3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAQcEeDlvgjV",
        "outputId": "8cd390fd-9d1b-4406-83ee-76620c413c5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3126, 0.3791],\n",
            "        [0.3087, 0.0736]])\n",
            "tensor([[0.4216, 0.0691],\n",
            "        [0.2332, 0.4047]])\n",
            "tensor([[0.3126, 0.3791],\n",
            "        [0.3087, 0.0736]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(2,3)\n",
        "print(ones)\n",
        "\n",
        "twos = torch.ones(2,3) +2\n",
        "print(twos)\n",
        "\n",
        "threes = ones + twos\n",
        "print(threes)\n",
        "print(threes.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqwLZtNZwZwN",
        "outputId": "cfeeb588-597e-4c54-fa60-5f959a74939a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.]])\n",
            "tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = torch.rand(2,2) - 0.5 * 2\n",
        "print(\"A random matrix, r: {}\".format(r))\n",
        "print(\"\\nAbsolute value of r: {}\".format(torch.abs(r)))\n",
        "print(\"\\nInverse sine of r: {}\".format(torch.abs(r)))\n",
        "print(\"\\nDetermined of r: {}\".format(torch.det(r)))\n",
        "print(\"\\nSingular Value decomposition of r: {}\".format(torch.svd(r)))\n",
        "print(\"\\nAverage and standard deviation of r: {}\".format(torch.std_mean(r)))\n",
        "print(\"\\nMaximum value of r: {}\".format(torch.max(r)))"
      ],
      "metadata": {
        "id": "7gRAehOVwbNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5df4a9-2de9-4adc-bf54-3ef1830a4ed5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A random matrix, r: tensor([[-0.5784, -0.9309],\n",
            "        [-0.7668, -0.5953]])\n",
            "\n",
            "Absolute value of r: tensor([[0.5784, 0.9309],\n",
            "        [0.7668, 0.5953]])\n",
            "\n",
            "Inverse sine of r: tensor([[0.5784, 0.9309],\n",
            "        [0.7668, 0.5953]])\n",
            "\n",
            "Determined of r: -0.36948588490486145\n",
            "\n",
            "Singular Value decomposition of r: torch.return_types.svd(\n",
            "U=tensor([[-0.7512, -0.6601],\n",
            "        [-0.6601,  0.7512]]),\n",
            "S=tensor([1.4415, 0.2563]),\n",
            "V=tensor([[ 0.6525, -0.7578],\n",
            "        [ 0.7578,  0.6525]]))\n",
            "\n",
            "Average and standard deviation of r: (tensor(0.1656), tensor(-0.7179))\n",
            "\n",
            "Maximum value of r: -0.5783984065055847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd"
      ],
      "metadata": {
        "id": "Pt1zix1-995R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1,10)\n",
        "prev_h =torch.randn(1,20)\n",
        "W_h = torch.randn(20,20)\n",
        "W_x = torch.randn(20,10)"
      ],
      "metadata": {
        "id": "b35qQhoU99RZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i2h = torch.mm(W_x, x.t())\n",
        "h2h = torch.mm(W_h, prev_h.t())\n",
        "next_h = i2h + h2h\n",
        "next_h = next_h.tanh()"
      ],
      "metadata": {
        "id": "y8GqzPfH77u6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = next_h.sum()"
      ],
      "metadata": {
        "id": "KBpxw54478Cv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A pytorch model"
      ],
      "metadata": {
        "id": "qSnzVHBmaeMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "WGpEL6lZa_-u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    # kernel\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "    # y = wx + b\n",
        "    self.fc1 = nn.Linear(16*6*6, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 =nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g7X0e6obbJeO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = LeNet()\n",
        "print(net)"
      ],
      "metadata": {
        "id": "_vwcrWq7ox_K",
        "outputId": "c1c311ca-2d2d-4255-9004-c3f74bd67b3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.rand(1,1,32,32)\n",
        "print(input.shape)"
      ],
      "metadata": {
        "id": "GLX0-ISvo7jG",
        "outputId": "10bac4ec-6449-4bd4-e128-c928339dff88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = net(input)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "9PdkEBdKpL-0",
        "outputId": "47084bca-dffe-4795-f023-ce3d9c76e680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0302, -0.0182,  0.0408, -0.0674,  0.1178,  0.1091,  0.1661, -0.0017,\n",
            "         -0.0024, -0.1007]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Linear(20, 30)\n",
        "input = torch.randn(128, 20)\n",
        "output = m(input)"
      ],
      "metadata": {
        "id": "NXWTYar0cF3X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clky1T5mFYKz",
        "outputId": "a38b3237-da82-4b52-ae7d-e59913133b1e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2227,  0.8130,  0.1647,  ...,  0.0536, -1.1111, -0.3371],\n",
              "        [ 0.3362,  0.1273,  0.8467,  ..., -0.3185,  0.5817,  0.0139],\n",
              "        [ 0.1310, -0.0372,  0.7539,  ...,  0.2026,  0.2680, -0.0638],\n",
              "        ...,\n",
              "        [ 0.1727, -0.0705,  0.6596,  ...,  0.1967,  0.4436, -0.0565],\n",
              "        [ 0.5673, -0.9753,  0.9595,  ...,  0.2694, -0.4400, -0.3557],\n",
              "        [-0.9148,  0.9221,  0.1894,  ...,  0.0949, -0.0098, -0.5137]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.MaxPool2d(3, stride=2)\n",
        "input = torch.randn(20, 16,20)\n",
        "output = m(input)"
      ],
      "metadata": {
        "id": "4M_2osbgGJeq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybKn-Q2RJGWj",
        "outputId": "b95b856c-00f5-4970-c214-45444c26213a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About pooling\n",
        "1. The pooling operation involves sliding a two-dimensional filter over each channel of feature map and summarizing the features lying within the region by the filter.\n",
        "2. A CNN model architecture is to have a number of convolution and pooling layers stacked one after the other\n",
        "3. Pooling layer are used to reduce the dimensions of the feature maps. Thus, it reduce the numbers of parameters to learn and the amount of computation in the network.\n",
        "4. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer. So, further operation are performed on summarised features instead of precisely positioned features generated by the convolution layer.\n",
        "\n",
        "## Types of pooling layer\n",
        "1. Max pooling, a pooling operation to select the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous map.\n",
        "2. Average pooling computes the average of the elements present in the region of feature map covered by the filter.\n",
        "3. Global pooling ?\n",
        "\n"
      ],
      "metadata": {
        "id": "f339o0ZzeZ0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Max pooling\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import MaxPooling2D, AveragePooling2D\n",
        "\n",
        "image = np.array([\n",
        "                  [2, 3, 4, 5],\n",
        "                  [9, 4, 6, 1],\n",
        "                  [8, 5, 2, 4],\n",
        "                  [3, 1, 2, 6]\n",
        "                  ])\n",
        "image = image.reshape(1, 4, 4, 1)\n",
        "\n",
        "model_max = Sequential([MaxPooling2D(pool_size=2, strides=2)])\n",
        "\n",
        "model_average = Sequential([AveragePooling2D(pool_size=2, strides=2)])\n",
        "\n",
        "output_max = model_max.predict(image)\n",
        "\n",
        "output_average = model_average.predict(image)"
      ],
      "metadata": {
        "id": "3AnYWpzzc2zW",
        "outputId": "a5af8563-e10e-4d49-a6ec-e57058e74c65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The max-pooling output is {}\".format(np.squeeze(output_average)))\n",
        "print(\"\\nThe average-pooling output is {}\".format(np.squeeze(output_average)))\n"
      ],
      "metadata": {
        "id": "GvAUeDrZst9_",
        "outputId": "d5b4f547-5b06-4d10-fbde-5aae61d6c161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max-pooling output is [[4.5  4.  ]\n",
            " [4.25 3.5 ]]\n",
            "\n",
            "The average-pooling output is [[4.5  4.  ]\n",
            " [4.25 3.5 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# torch.nn.Module\n",
        "Base class for all neural network module, self-defined models should subclass this class"
      ],
      "metadata": {
        "id": "3iDu8GwkrR07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "spv3jOuokuDE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 20, 5)\n",
        "    self.conv2 = nn.Conv2d(20, 20, 5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    return F.relu(self.conv2(x))"
      ],
      "metadata": {
        "id": "w2bPjWxnrp0v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is convolution\n",
        "Convolution is a mathematical operation that combines two functions to describe the overlap between them. Convolution takes two functions and slides one of them over the other, multiplying the function values at each point where they overlap, and adding up the products to create a new function."
      ],
      "metadata": {
        "id": "H0ELIivc3K_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dsQyDWPz7IlT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = np.array([np.array([200, 200]), np.array([200, 200])])\n",
        "img2 = np.array([np.array([200, 200]), np.array([0, 0])])\n",
        "img3 = np.array([np.array([200, 0]), np.array([200, 0])])\n",
        "\n",
        "kernel_horizontal = np.array([np.array([2,2]), np.array([-2,-2])])"
      ],
      "metadata": {
        "id": "d7TCCKs-3hFE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1\n",
        "img2\n",
        "img3"
      ],
      "metadata": {
        "id": "L5c01rWr7zMf",
        "outputId": "c45dee80-4581-4ab3-b362-a68637d79acb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[200,   0],\n",
              "       [200,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2u-xlcv49OpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "viJ9-odf7o57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Conv2d"
      ],
      "metadata": {
        "id": "kjTEgMvSsVHm",
        "outputId": "962cd4c0-0fd0-4669-9c26-7c0595b913b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.conv.Conv2d"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.conv.Conv2d</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py</a>Applies a 2D convolution over an input signal composed of several input\n",
              "planes.\n",
              "\n",
              "In the simplest case, the output value of the layer with input size\n",
              ":math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
              "can be precisely described as:\n",
              "\n",
              ".. math::\n",
              "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
              "    \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
              "\n",
              "\n",
              "where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
              ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
              ":math:`H` is a height of input planes in pixels, and :math:`W` is\n",
              "width in pixels.\n",
              "\n",
              "\n",
              "This module supports :ref:`TensorFloat32&lt;tf32_on_ampere&gt;`.\n",
              "\n",
              "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision&lt;fp16_on_mi200&gt;` for backward.\n",
              "\n",
              "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
              "  number or a tuple.\n",
              "\n",
              "* :attr:`padding` controls the amount of padding applied to the input. It\n",
              "  can be either a string {&#x27;valid&#x27;, &#x27;same&#x27;} or an int / a tuple of ints giving the\n",
              "  amount of implicit padding applied on both sides.\n",
              "\n",
              "* :attr:`dilation` controls the spacing between the kernel points; also\n",
              "  known as the \\u00e0 trous algorithm. It is harder to describe, but this `link`_\n",
              "  has a nice visualization of what :attr:`dilation` does.\n",
              "\n",
              "* :attr:`groups` controls the connections between inputs and outputs.\n",
              "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
              "  :attr:`groups`. For example,\n",
              "\n",
              "    * At groups=1, all inputs are convolved to all outputs.\n",
              "    * At groups=2, the operation becomes equivalent to having two conv\n",
              "      layers side by side, each seeing half the input channels\n",
              "      and producing half the output channels, and both subsequently\n",
              "      concatenated.\n",
              "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
              "      its own set of filters (of size\n",
              "      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
              "\n",
              "The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
              "\n",
              "    - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
              "    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
              "      and the second `int` for the width dimension\n",
              "\n",
              "Note:\n",
              "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
              "    where `K` is a positive integer, this operation is also known as a &quot;depthwise convolution&quot;.\n",
              "\n",
              "    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
              "    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
              "    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
              "\n",
              "Note:\n",
              "    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
              "\n",
              "Note:\n",
              "    ``padding=&#x27;valid&#x27;`` is the same as no padding. ``padding=&#x27;same&#x27;`` pads\n",
              "    the input so the output has the shape as the input. However, this mode\n",
              "    doesn&#x27;t support any stride values other than 1.\n",
              "\n",
              "Note:\n",
              "    This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
              "\n",
              "Args:\n",
              "    in_channels (int): Number of channels in the input image\n",
              "    out_channels (int): Number of channels produced by the convolution\n",
              "    kernel_size (int or tuple): Size of the convolving kernel\n",
              "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
              "    padding (int, tuple or str, optional): Padding added to all four sides of\n",
              "        the input. Default: 0\n",
              "    padding_mode (str, optional): ``&#x27;zeros&#x27;``, ``&#x27;reflect&#x27;``,\n",
              "        ``&#x27;replicate&#x27;`` or ``&#x27;circular&#x27;``. Default: ``&#x27;zeros&#x27;``\n",
              "    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
              "    groups (int, optional): Number of blocked connections from input\n",
              "        channels to output channels. Default: 1\n",
              "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
              "        output. Default: ``True``\n",
              "\n",
              "\n",
              "Shape:\n",
              "    - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
              "    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
              "\n",
              "      .. math::\n",
              "          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
              "                    \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
              "\n",
              "      .. math::\n",
              "          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
              "                    \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
              "\n",
              "Attributes:\n",
              "    weight (Tensor): the learnable weights of the module of shape\n",
              "        :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
              "        :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
              "        The values of these weights are sampled from\n",
              "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
              "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
              "    bias (Tensor):   the learnable bias of the module of shape\n",
              "        (out_channels). If :attr:`bias` is ``True``,\n",
              "        then the values of these weights are\n",
              "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
              "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
              "\n",
              "Examples:\n",
              "\n",
              "    &gt;&gt;&gt; # With square kernels and equal stride\n",
              "    &gt;&gt;&gt; m = nn.Conv2d(16, 33, 3, stride=2)\n",
              "    &gt;&gt;&gt; # non-square kernels and unequal stride and with padding\n",
              "    &gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
              "    &gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation\n",
              "    &gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
              "    &gt;&gt;&gt; input = torch.randn(20, 16, 50, 100)\n",
              "    &gt;&gt;&gt; output = m(input)\n",
              "\n",
              ".. _cross-correlation:\n",
              "    https://en.wikipedia.org/wiki/Cross-correlation\n",
              "\n",
              ".. _link:\n",
              "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 311);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0RteRGY0smsY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}